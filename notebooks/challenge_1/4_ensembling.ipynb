{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZK2rYtCSgEl",
    "outputId": "3d62062a-978d-4839-96b9-a6e5e4c71bb0"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "data_home = \"../../artefacts/data\"\n",
    "model_home = \"../../artefacts/models/challenge_1\"\n",
    "\n",
    "SFREQ = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validator:\n",
    "    def __init__(self, valid_loader, target):\n",
    "        self.valid_loader = valid_loader\n",
    "        self.target = torch.as_tensor(target, dtype=torch.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def z_to_predict(z, temperature=0.1):\n",
    "        \"\"\"softargmax предсказание на torch\"\"\"\n",
    "        T = z.shape[-1]\n",
    "        dt = 1 / 100\n",
    "        win_offset = 0.5\n",
    "        p = F.softmax(z / temperature, dim=-1)\n",
    "        t_grid = torch.arange(T, device=z.device, dtype=z.dtype)[None, :] * dt\n",
    "        t_hat_rel = (p * t_grid).sum(dim=-1)\n",
    "        t_hat_abs = (t_hat_rel + win_offset).view(-1)\n",
    "        return t_hat_abs\n",
    "\n",
    "    @staticmethod\n",
    "    def entropy_from_logits(z, temperature=1.0, eps=1e-12):\n",
    "        \"\"\"Энтропия распределений softmax по времени\"\"\"\n",
    "        p = F.softmax(z / temperature, dim=-1)\n",
    "        ent = -(p * (p.clamp_min(eps)).log()).sum(dim=-1)\n",
    "        return ent\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate_model(self, model, device='cuda', temperature=1.0):\n",
    "        logits = []\n",
    "        preds = []\n",
    "        model.eval()\n",
    "        for batch in tqdm(self.valid_loader):\n",
    "            x = batch[0][:, :128, :].to(device).float()\n",
    "            z = model(x).squeeze(1)  # (B,T)\n",
    "            logits.append(z.cpu())\n",
    "            preds.append(self.z_to_predict(z, temperature).cpu())\n",
    "        logits = torch.cat(logits, dim=0)\n",
    "        preds = torch.cat(preds, dim=0)\n",
    "        _, nrmse, entropy = self.validate_logits(logits, temperature)\n",
    "        return logits, preds, nrmse, entropy\n",
    "\n",
    "    def validate_logits(self, logits, temperature):\n",
    "        preds = self.z_to_predict(logits, temperature)\n",
    "        entropy = self.entropy_from_logits(logits, temperature)\n",
    "        rmse = torch.sqrt(((preds - self.target.to(preds.device)) ** 2).mean())\n",
    "        nrmse = rmse / self.target.std()\n",
    "        return preds, nrmse, entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the validation dataset\n",
    "\n",
    "We not trained anything on our relatively big validation dataset (20% of subjects)\n",
    "\n",
    "So now finally time to take advantage from this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_home, \"valid_dataset.pkl\"), \"rb\") as f:\n",
    "    valid_dataset = pickle.load(f)\n",
    "\n",
    "meta_information_valid = valid_dataset.get_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching the best folds split to have similar mean values across all folds\n",
    "\n",
    "Should be reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching permutations for lowest std: 100%|██████████| 10000/10000 [01:12<00:00, 138.65it/s, best_std=0.00242]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best permutation found | std of fold target means: 0.002420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    1.592597\n",
       "1    1.592596\n",
       "2     1.58827\n",
       "3    1.589053\n",
       "4    1.587539\n",
       "Name: target, dtype: Float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "# Compute per-subject mean target\n",
    "subject_means = meta_information_valid.groupby('subject').target.mean()\n",
    "subjects = subject_means.index.values\n",
    "targets = subject_means.values\n",
    "n_subjects = len(subjects)\n",
    "n_folds = 5\n",
    "\n",
    "# Create uniformly distributed initial fold assignments\n",
    "base_fold_assignments = np.arange(n_subjects) % n_folds\n",
    "\n",
    "# Generate permutations and search for the permutation with lowest std of fold means\n",
    "best_std = float('inf')\n",
    "best_permutation = None\n",
    "best_subject_to_fold = None\n",
    "\n",
    "# Approach: for 1000 iterations, permute fold assignments (uniform weights) and compute std\n",
    "rng = np.random.default_rng(seed=42)\n",
    "progress_bar = tqdm(range(10000), desc='Searching permutations for lowest std')\n",
    "for _ in progress_bar:\n",
    "    permuted_assignments = np.copy(base_fold_assignments)\n",
    "    rng.shuffle(permuted_assignments)\n",
    "    subject_to_fold = dict(zip(subjects, permuted_assignments))\n",
    "    fold_assignments = meta_information_valid['subject'].map(subject_to_fold).values\n",
    "    mean_per_fold = meta_information_valid.assign(fold=fold_assignments).groupby('fold').target.mean()\n",
    "    fold_std = mean_per_fold.std()\n",
    "    if fold_std < best_std:\n",
    "        best_std = fold_std\n",
    "        best_permutation = permuted_assignments.copy()\n",
    "        best_subject_to_fold = subject_to_fold.copy()\n",
    "        progress_bar.set_postfix(best_std=best_std)\n",
    "\n",
    "# Assign best fold split to dataframe\n",
    "meta_information_valid['fold'] = meta_information_valid['subject'].map(best_subject_to_fold).values\n",
    "print(f\"Best permutation found | std of fold target means: {best_std:.6f}\")\n",
    "display(meta_information_valid.groupby('fold').target.mean())\n",
    "# meta_information_valid.to_csv('meta_valid_with_folds.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "validator = Validator(valid_loader, meta_information_valid['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181/181 [00:04<00:00, 36.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE: 0.902532 for unet_deeper_widen4_v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181/181 [00:04<00:00, 40.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE: 0.898900 for unet_deeper_v4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181/181 [00:04<00:00, 39.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE: 0.903785 for unet_v4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181/181 [00:07<00:00, 23.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE: 0.901511 for attention_unet_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181/181 [00:04<00:00, 40.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE: 0.917440 for inception_v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181/181 [00:09<00:00, 19.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE: 0.910516 for factorization_unet_v1_finetune\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from neurosned.models.segmentation.factorization_unet import FactorizationSneddyUnet\n",
    "from neurosned.models.segmentation.sneddy_unet import SneddySegUNet1D\n",
    "from neurosned.models.segmentation.inception import EEGInceptionSeg1D\n",
    "from neurosned.models.segmentation.attention_sneddy_unet import AttentionSneddyUnet\n",
    "\n",
    "# unet_deeper_widen4_v0 - 903.4\n",
    "# unet_deeper_widen4_v1 - 902.532\n",
    "model_1 = SneddySegUNet1D(\n",
    "    n_chans=128, n_times=200, sfreq=100,\n",
    "    c0=64, widen=4, depth_per_stage=5, dropout=0.05, k=15,\n",
    "    out_channels=1\n",
    ").to(device)\n",
    "model_1_weights = [\n",
    "    \"unet_deeper_widen4_v1\"\n",
    "]\n",
    "\n",
    "# # unet_deeper_v0 - 903.320\n",
    "# # unet_deeper_v1 - 901.810\n",
    "# # unet_deeper_v3 - 899.418\n",
    "# # unet_deeper_v4 - 898.900\n",
    "# # unet_deeper_v5 - 898.618\n",
    "model_2 = SneddySegUNet1D(\n",
    "    n_chans=128, n_times=200, sfreq=100,\n",
    "    c0=96, widen=2, depth_per_stage=5, dropout=0.05, k=15,\n",
    "    out_channels=1\n",
    ").to(device)\n",
    "model_2_weights = [\n",
    "    'unet_deeper_v4', \n",
    "]\n",
    "\n",
    "model_3 = SneddySegUNet1D(\n",
    "    n_chans=128, n_times=200, sfreq=100,\n",
    "    c0=96, widen=2, depth_per_stage=3, dropout=0.05, k=15,\n",
    "    out_channels=1\n",
    ").to(device)\n",
    "model_3_weights = [\"unet_v4\"] \n",
    "\n",
    "# attention_unet_v1 - 902.554\n",
    "# attention_unet_v2 - 901.512\n",
    "# attention_unet_v4 - 901.503\n",
    "model_4 = AttentionSneddyUnet(\n",
    "    n_chans=128, n_times=200, sfreq=100,\n",
    "    c0=64, num_stages=5, widen=2.0, depth_per_stage=[2,2,2,1,1],\n",
    "    bottleneck_type=\"mhsa\", bottleneck_depth=3,\n",
    "    attn_heads=4, attn_dropout=0.05, ffn_dropout=0.05,\n",
    "    drop_path=0.1, skip_gating=True\n",
    ").to(device)\n",
    "model_4_weights = [\n",
    "    'attention_unet_v2',\n",
    "]\n",
    "\n",
    "# Inception-style model\n",
    "model_5 = EEGInceptionSeg1D(\n",
    "    n_chans=128, n_times=200, sfreq=100,\n",
    "    branch_out=32,\n",
    "    scales_samples_s=(0.5, 0.25, 0.125),\n",
    "    pooling_sizes=(1, 1),\n",
    "    dropout=0.12,\n",
    "    out_channels=1\n",
    ").to(device)\n",
    "model_5_weights = [\n",
    "    \"inception_v0\"\n",
    "]\n",
    "\n",
    "# Factorization U-Net style model\n",
    "model_6 = FactorizationSneddyUnet(\n",
    "    n_chans=128, n_times=200, sfreq=100, c0=96, widen=2,\n",
    "    n_stages=4,\n",
    "    depth_per_stage=2, dropout=0.1, k=7, out_channels=1,\n",
    "    fm_factors_front=64, fm_dropout_front=0.05,\n",
    "    use_stage_fm=True,\n",
    "    fm_factors_stage=32, fm_dropout_stage=0.05\n",
    ").to(device)\n",
    "model_6_weights = [\n",
    "    \"factorization_unet_v1_finetune\",\n",
    "]\n",
    "\n",
    "model_weights_store = (\n",
    "    (model_1, model_1_weights),\n",
    "    (model_2, model_2_weights),\n",
    "    (model_3, model_3_weights),\n",
    "    (model_4, model_4_weights),\n",
    "    (model_5, model_5_weights),\n",
    "    (model_6, model_6_weights)\n",
    ")\n",
    "\n",
    "logits_store = {}\n",
    "# entropy_store = {}\n",
    "nrmse_store = {}\n",
    "for model, model_fnames in model_weights_store:\n",
    "    for fname in model_fnames:\n",
    "        fpath = os.path.join(model_home, fname) + '.pth'\n",
    "        current_state_dict = torch.load(fpath)\n",
    "        model.load_state_dict(current_state_dict)\n",
    "        logits, preds, nrmse, entropy = validator.validate_model(model)\n",
    "        logits_store[fname] = logits\n",
    "        nrmse_store[fname] = nrmse\n",
    "        print(f\"NRMSE: {nrmse:.6f} for {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_models_nrmse(logits_store, targets, device=None, dt=1/100, win_offset=0.5):\n",
    "    \"\"\"\n",
    "    Считает дефолтный и откалиброванный (по температуре) NRMSE для каждой модели в logits_store.\n",
    "\n",
    "    logits_store: dict[str, np.ndarray или torch.Tensor], формы (N, T)\n",
    "    targets: array-like длиной N (в секундах)\n",
    "    device: 'cuda' или 'cpu'\n",
    "    \"\"\"\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    y = torch.as_tensor(targets, dtype=torch.float32, device=device)\n",
    "    results = {}\n",
    "\n",
    "    for name, logits in tqdm(logits_store.items(), desc=\"Evaluating models\"):\n",
    "        z = torch.as_tensor(logits, dtype=torch.float32, device=device)\n",
    "        N, T = z.shape\n",
    "        t_grid = torch.arange(T, device=device, dtype=torch.float32)[None, :] * dt\n",
    "\n",
    "        # === 1. дефолтная температура (1.0) ===\n",
    "        p = F.softmax(z / 1.0, dim=-1)\n",
    "        t_hat = (p * t_grid).sum(dim=-1) + win_offset\n",
    "        rmse = torch.sqrt(((t_hat - y) ** 2).mean())\n",
    "        nrmse_def = (rmse / y.std()).item()\n",
    "\n",
    "        # === 2. подбор температуры (грид-серч) ===\n",
    "        best_T, best_nrmse = 1.0, nrmse_def\n",
    "        for T in torch.linspace(0.4, 1.8, 30, device=device):  # сетка температур\n",
    "            pT = F.softmax(z / T, dim=-1)\n",
    "            t_hat_T = (pT * t_grid).sum(dim=-1) + win_offset\n",
    "            rmse_T = torch.sqrt(((t_hat_T - y) ** 2).mean())\n",
    "            nrmse_T = (rmse_T / y.std()).item()\n",
    "            if nrmse_T < best_nrmse:\n",
    "                best_nrmse, best_T = nrmse_T, float(T)\n",
    "\n",
    "        results[name] = {\n",
    "            \"default_nrmse\": nrmse_def,\n",
    "            \"calibrated_nrmse\": best_nrmse,\n",
    "            \"best_temperature\": best_T\n",
    "        }\n",
    "\n",
    "    # красивый вывод\n",
    "    print(f\"\\n{'Model':30s} {'NRMSE_def':>12s} {'NRMSE_cal':>12s} {'Best_T':>8s}\")\n",
    "    print(\"-\" * 70)\n",
    "    for name, vals in results.items():\n",
    "        print(f\"{name:30s} {vals['default_nrmse']:.6f} {vals['calibrated_nrmse']:.6f} {vals['best_temperature']:.3f}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models: 100%|██████████| 6/6 [00:00<00:00, 141.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                             NRMSE_def    NRMSE_cal   Best_T\n",
      "----------------------------------------------------------------------\n",
      "unet_deeper_widen4_v1          0.902532 0.902324 1.076\n",
      "unet_deeper_v4                 0.898900 0.898757 1.076\n",
      "unet_v4                        0.903785 0.903785 1.000\n",
      "attention_unet_v2              0.901511 0.901511 1.028\n",
      "inception_v0                   0.917440 0.916910 1.124\n",
      "factorization_unet_v1_finetune 0.910516 0.909281 1.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "targets = torch.as_tensor(meta_information_valid['target'].values, dtype=torch.float32)\n",
    "results = evaluate_models_nrmse(logits_store, targets, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: RMSE 0.340538 | NRMSE 0.839932 | n=4649\n",
      "Fold 1: RMSE 0.358408 | NRMSE 0.884007 | n=4467\n",
      "Fold 2: RMSE 0.365506 | NRMSE 0.901516 | n=4590\n",
      "Fold 3: RMSE 0.383917 | NRMSE 0.946925 | n=4674\n",
      "Fold 4: RMSE 0.362830 | NRMSE 0.894915 | n=4669\n",
      "OOF  : RMSE 0.362555 | NRMSE 0.894237 | n=23049\n"
     ]
    }
   ],
   "source": [
    "from neurosned.wrappers.challenge_1.meta_regressor import RidgeMetaRegressor\n",
    "from neurosned.wrappers.challenge_1.meta_features import MetaFeatureExtractor\n",
    "\n",
    "fx_ridge = MetaFeatureExtractor(sfreq=100, win_offset=0.5, temps=(0.6, 1.0, 0.8))\n",
    "X_train = fx_ridge.build_from_logits_store(logits_store, cls_outputs_store=None)\n",
    "\n",
    "reg = RidgeMetaRegressor()     \n",
    "folds = meta_information_valid.fold.values\n",
    "reg.fit(X_train, meta_information_valid['target'].values, folds=folds)\n",
    "reg.save(\"../../artefacts/models/challenge_1/meta_ridge_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurosned.wrappers.challenge_1.meta_wrapper import MetaWrapper\n",
    "from neurosned.wrappers.challenge_1.meta_regressor import MetaRegressor\n",
    "\n",
    "seg_models = [model_1, model_2, model_3, model_4, model_5, model_6]  # ваши torch-модели\n",
    "reg = MetaRegressor.load(\"../../artefacts/models/challenge_1/meta_ridge_new.pkl\")\n",
    "\n",
    "meta_ridge = MetaWrapper(seg_models=seg_models, cls_models=[],\n",
    "                   feature_extractor=fx_ridge, meta_regressor=reg,\n",
    "                   use_channels=np.arange(128), device=device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def make_monotonic_constraints(feature_names, time_dir=1):\n",
    "    \"\"\"\n",
    "    time_dir: 1 для времени-«вперёд», -1 если таргет убывает с реальным временем.\n",
    "    \"\"\"\n",
    "    cst = []\n",
    "    for n in feature_names:\n",
    "        is_time = (\n",
    "            n.endswith(\"t_hard\")\n",
    "            or (\"t_abs_temp\" in n)\n",
    "            or bool(re.search(r\"q\\d+_temp\", n))\n",
    "        )\n",
    "        cst.append(time_dir if is_time else 0)\n",
    "    return np.asarray(cst, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0\n",
      " 0 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1\n",
      " 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0\n",
      " 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0\n",
      " 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 1\n",
      " 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1]\n",
      "['seg_unet_deeper_widen4_v1_t_hard', 'seg_unet_deeper_widen4_v1_z_max', 'seg_unet_deeper_widen4_v1_z_margin', 'seg_unet_deeper_widen4_v1_t_abs_temp0.5', 'seg_unet_deeper_widen4_v1_ent_temp0.5', 'seg_unet_deeper_widen4_v1_pmax_temp0.5', 'seg_unet_deeper_widen4_v1_pmargin_temp0.5', 'seg_unet_deeper_widen4_v1_tvar_temp0.5', 'seg_unet_deeper_widen4_v1_q10_temp0.5', 'seg_unet_deeper_widen4_v1_q50_temp0.5', 'seg_unet_deeper_widen4_v1_q90_temp0.5', 'seg_unet_deeper_widen4_v1_t_abs_temp0.7', 'seg_unet_deeper_widen4_v1_ent_temp0.7', 'seg_unet_deeper_widen4_v1_pmax_temp0.7', 'seg_unet_deeper_widen4_v1_pmargin_temp0.7', 'seg_unet_deeper_widen4_v1_tvar_temp0.7', 'seg_unet_deeper_widen4_v1_q10_temp0.7', 'seg_unet_deeper_widen4_v1_q50_temp0.7', 'seg_unet_deeper_widen4_v1_q90_temp0.7', 'seg_unet_deeper_widen4_v1_t_abs_temp0.8', 'seg_unet_deeper_widen4_v1_ent_temp0.8', 'seg_unet_deeper_widen4_v1_pmax_temp0.8', 'seg_unet_deeper_widen4_v1_pmargin_temp0.8', 'seg_unet_deeper_widen4_v1_tvar_temp0.8', 'seg_unet_deeper_widen4_v1_q10_temp0.8', 'seg_unet_deeper_widen4_v1_q50_temp0.8', 'seg_unet_deeper_widen4_v1_q90_temp0.8', 'seg_unet_deeper_widen4_v1_t_abs_temp1.0', 'seg_unet_deeper_widen4_v1_ent_temp1.0', 'seg_unet_deeper_widen4_v1_pmax_temp1.0', 'seg_unet_deeper_widen4_v1_pmargin_temp1.0', 'seg_unet_deeper_widen4_v1_tvar_temp1.0', 'seg_unet_deeper_widen4_v1_q10_temp1.0', 'seg_unet_deeper_widen4_v1_q50_temp1.0', 'seg_unet_deeper_widen4_v1_q90_temp1.0', 'seg_unet_deeper_v4_t_hard', 'seg_unet_deeper_v4_z_max', 'seg_unet_deeper_v4_z_margin', 'seg_unet_deeper_v4_t_abs_temp0.5', 'seg_unet_deeper_v4_ent_temp0.5', 'seg_unet_deeper_v4_pmax_temp0.5', 'seg_unet_deeper_v4_pmargin_temp0.5', 'seg_unet_deeper_v4_tvar_temp0.5', 'seg_unet_deeper_v4_q10_temp0.5', 'seg_unet_deeper_v4_q50_temp0.5', 'seg_unet_deeper_v4_q90_temp0.5', 'seg_unet_deeper_v4_t_abs_temp0.7', 'seg_unet_deeper_v4_ent_temp0.7', 'seg_unet_deeper_v4_pmax_temp0.7', 'seg_unet_deeper_v4_pmargin_temp0.7', 'seg_unet_deeper_v4_tvar_temp0.7', 'seg_unet_deeper_v4_q10_temp0.7', 'seg_unet_deeper_v4_q50_temp0.7', 'seg_unet_deeper_v4_q90_temp0.7', 'seg_unet_deeper_v4_t_abs_temp0.8', 'seg_unet_deeper_v4_ent_temp0.8', 'seg_unet_deeper_v4_pmax_temp0.8', 'seg_unet_deeper_v4_pmargin_temp0.8', 'seg_unet_deeper_v4_tvar_temp0.8', 'seg_unet_deeper_v4_q10_temp0.8', 'seg_unet_deeper_v4_q50_temp0.8', 'seg_unet_deeper_v4_q90_temp0.8', 'seg_unet_deeper_v4_t_abs_temp1.0', 'seg_unet_deeper_v4_ent_temp1.0', 'seg_unet_deeper_v4_pmax_temp1.0', 'seg_unet_deeper_v4_pmargin_temp1.0', 'seg_unet_deeper_v4_tvar_temp1.0', 'seg_unet_deeper_v4_q10_temp1.0', 'seg_unet_deeper_v4_q50_temp1.0', 'seg_unet_deeper_v4_q90_temp1.0', 'seg_unet_v4_t_hard', 'seg_unet_v4_z_max', 'seg_unet_v4_z_margin', 'seg_unet_v4_t_abs_temp0.5', 'seg_unet_v4_ent_temp0.5', 'seg_unet_v4_pmax_temp0.5', 'seg_unet_v4_pmargin_temp0.5', 'seg_unet_v4_tvar_temp0.5', 'seg_unet_v4_q10_temp0.5', 'seg_unet_v4_q50_temp0.5', 'seg_unet_v4_q90_temp0.5', 'seg_unet_v4_t_abs_temp0.7', 'seg_unet_v4_ent_temp0.7', 'seg_unet_v4_pmax_temp0.7', 'seg_unet_v4_pmargin_temp0.7', 'seg_unet_v4_tvar_temp0.7', 'seg_unet_v4_q10_temp0.7', 'seg_unet_v4_q50_temp0.7', 'seg_unet_v4_q90_temp0.7', 'seg_unet_v4_t_abs_temp0.8', 'seg_unet_v4_ent_temp0.8', 'seg_unet_v4_pmax_temp0.8', 'seg_unet_v4_pmargin_temp0.8', 'seg_unet_v4_tvar_temp0.8', 'seg_unet_v4_q10_temp0.8', 'seg_unet_v4_q50_temp0.8', 'seg_unet_v4_q90_temp0.8', 'seg_unet_v4_t_abs_temp1.0', 'seg_unet_v4_ent_temp1.0', 'seg_unet_v4_pmax_temp1.0', 'seg_unet_v4_pmargin_temp1.0', 'seg_unet_v4_tvar_temp1.0', 'seg_unet_v4_q10_temp1.0', 'seg_unet_v4_q50_temp1.0', 'seg_unet_v4_q90_temp1.0', 'seg_attention_unet_v2_t_hard', 'seg_attention_unet_v2_z_max', 'seg_attention_unet_v2_z_margin', 'seg_attention_unet_v2_t_abs_temp0.5', 'seg_attention_unet_v2_ent_temp0.5', 'seg_attention_unet_v2_pmax_temp0.5', 'seg_attention_unet_v2_pmargin_temp0.5', 'seg_attention_unet_v2_tvar_temp0.5', 'seg_attention_unet_v2_q10_temp0.5', 'seg_attention_unet_v2_q50_temp0.5', 'seg_attention_unet_v2_q90_temp0.5', 'seg_attention_unet_v2_t_abs_temp0.7', 'seg_attention_unet_v2_ent_temp0.7', 'seg_attention_unet_v2_pmax_temp0.7', 'seg_attention_unet_v2_pmargin_temp0.7', 'seg_attention_unet_v2_tvar_temp0.7', 'seg_attention_unet_v2_q10_temp0.7', 'seg_attention_unet_v2_q50_temp0.7', 'seg_attention_unet_v2_q90_temp0.7', 'seg_attention_unet_v2_t_abs_temp0.8', 'seg_attention_unet_v2_ent_temp0.8', 'seg_attention_unet_v2_pmax_temp0.8', 'seg_attention_unet_v2_pmargin_temp0.8', 'seg_attention_unet_v2_tvar_temp0.8', 'seg_attention_unet_v2_q10_temp0.8', 'seg_attention_unet_v2_q50_temp0.8', 'seg_attention_unet_v2_q90_temp0.8', 'seg_attention_unet_v2_t_abs_temp1.0', 'seg_attention_unet_v2_ent_temp1.0', 'seg_attention_unet_v2_pmax_temp1.0', 'seg_attention_unet_v2_pmargin_temp1.0', 'seg_attention_unet_v2_tvar_temp1.0', 'seg_attention_unet_v2_q10_temp1.0', 'seg_attention_unet_v2_q50_temp1.0', 'seg_attention_unet_v2_q90_temp1.0', 'seg_inception_v0_t_hard', 'seg_inception_v0_z_max', 'seg_inception_v0_z_margin', 'seg_inception_v0_t_abs_temp0.5', 'seg_inception_v0_ent_temp0.5', 'seg_inception_v0_pmax_temp0.5', 'seg_inception_v0_pmargin_temp0.5', 'seg_inception_v0_tvar_temp0.5', 'seg_inception_v0_q10_temp0.5', 'seg_inception_v0_q50_temp0.5', 'seg_inception_v0_q90_temp0.5', 'seg_inception_v0_t_abs_temp0.7', 'seg_inception_v0_ent_temp0.7', 'seg_inception_v0_pmax_temp0.7', 'seg_inception_v0_pmargin_temp0.7', 'seg_inception_v0_tvar_temp0.7', 'seg_inception_v0_q10_temp0.7', 'seg_inception_v0_q50_temp0.7', 'seg_inception_v0_q90_temp0.7', 'seg_inception_v0_t_abs_temp0.8', 'seg_inception_v0_ent_temp0.8', 'seg_inception_v0_pmax_temp0.8', 'seg_inception_v0_pmargin_temp0.8', 'seg_inception_v0_tvar_temp0.8', 'seg_inception_v0_q10_temp0.8', 'seg_inception_v0_q50_temp0.8', 'seg_inception_v0_q90_temp0.8', 'seg_inception_v0_t_abs_temp1.0', 'seg_inception_v0_ent_temp1.0', 'seg_inception_v0_pmax_temp1.0', 'seg_inception_v0_pmargin_temp1.0', 'seg_inception_v0_tvar_temp1.0', 'seg_inception_v0_q10_temp1.0', 'seg_inception_v0_q50_temp1.0', 'seg_inception_v0_q90_temp1.0', 'seg_factorization_unet_v1_finetune_t_hard', 'seg_factorization_unet_v1_finetune_z_max', 'seg_factorization_unet_v1_finetune_z_margin', 'seg_factorization_unet_v1_finetune_t_abs_temp0.5', 'seg_factorization_unet_v1_finetune_ent_temp0.5', 'seg_factorization_unet_v1_finetune_pmax_temp0.5', 'seg_factorization_unet_v1_finetune_pmargin_temp0.5', 'seg_factorization_unet_v1_finetune_tvar_temp0.5', 'seg_factorization_unet_v1_finetune_q10_temp0.5', 'seg_factorization_unet_v1_finetune_q50_temp0.5', 'seg_factorization_unet_v1_finetune_q90_temp0.5', 'seg_factorization_unet_v1_finetune_t_abs_temp0.7', 'seg_factorization_unet_v1_finetune_ent_temp0.7', 'seg_factorization_unet_v1_finetune_pmax_temp0.7', 'seg_factorization_unet_v1_finetune_pmargin_temp0.7', 'seg_factorization_unet_v1_finetune_tvar_temp0.7', 'seg_factorization_unet_v1_finetune_q10_temp0.7', 'seg_factorization_unet_v1_finetune_q50_temp0.7', 'seg_factorization_unet_v1_finetune_q90_temp0.7', 'seg_factorization_unet_v1_finetune_t_abs_temp0.8', 'seg_factorization_unet_v1_finetune_ent_temp0.8', 'seg_factorization_unet_v1_finetune_pmax_temp0.8', 'seg_factorization_unet_v1_finetune_pmargin_temp0.8', 'seg_factorization_unet_v1_finetune_tvar_temp0.8', 'seg_factorization_unet_v1_finetune_q10_temp0.8', 'seg_factorization_unet_v1_finetune_q50_temp0.8', 'seg_factorization_unet_v1_finetune_q90_temp0.8', 'seg_factorization_unet_v1_finetune_t_abs_temp1.0', 'seg_factorization_unet_v1_finetune_ent_temp1.0', 'seg_factorization_unet_v1_finetune_pmax_temp1.0', 'seg_factorization_unet_v1_finetune_pmargin_temp1.0', 'seg_factorization_unet_v1_finetune_tvar_temp1.0', 'seg_factorization_unet_v1_finetune_q10_temp1.0', 'seg_factorization_unet_v1_finetune_q50_temp1.0', 'seg_factorization_unet_v1_finetune_q90_temp1.0']\n",
      "Fold 0: RMSE 0.339361 | NRMSE 0.837027 | n=4649\n",
      "Fold 1: RMSE 0.356956 | NRMSE 0.880425 | n=4467\n",
      "Fold 2: RMSE 0.363902 | NRMSE 0.897557 | n=4590\n",
      "Fold 3: RMSE 0.382198 | NRMSE 0.942685 | n=4674\n",
      "Fold 4: RMSE 0.362785 | NRMSE 0.894802 | n=4669\n",
      "OOF  : RMSE 0.361354 | NRMSE 0.891273 | n=23049\n"
     ]
    }
   ],
   "source": [
    "from neurosned.wrappers.challenge_1.meta_regressor import HgbMetaRegressor\n",
    "from neurosned.wrappers.challenge_1.meta_features import MetaFeatureExtractor\n",
    "\n",
    "fx_hgbr = MetaFeatureExtractor(sfreq=100, win_offset=0.5, temps=(0.5, 0.7, 0.8, 1.))\n",
    "X_train, colnames = fx_hgbr.build_from_logits_store(logits_store, cls_outputs_store=None, return_names=True)\n",
    "cst = make_monotonic_constraints(colnames, time_dir=1)\n",
    "print(cst)\n",
    "print(colnames)\n",
    "defaults_hgbr = {\n",
    "    \"loss\": \"squared_error\",\n",
    "    \"quantile\": None,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"max_iter\": 2000,\n",
    "    \"max_leaf_nodes\": 20,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_samples_leaf\": 30,\n",
    "    \"l2_regularization\": 1.0,\n",
    "    \"max_features\": 0.1,\n",
    "    \"max_bins\": 100,\n",
    "    \"interaction_cst\": 'pairwise',\n",
    "    \"early_stopping\": \"auto\",\n",
    "    \"monotonic_cst\": cst,\n",
    "    \"scoring\": \"loss\",\n",
    "    \"validation_fraction\": None,\n",
    "    \"n_iter_no_change\": 50,\n",
    "    \"tol\": 1e-7,\n",
    "    \"verbose\": 0,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "reg = HgbMetaRegressor(hgb_params=defaults_hgbr)         \n",
    "folds = meta_information_valid.fold.values\n",
    "reg.fit(X_train, meta_information_valid['target'].values, folds=folds)\n",
    "reg.save(\"../../artefacts/models/challenge_1/meta_hgb_new.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Metrics ---\n",
    "def rmse(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=np.float32)\n",
    "    y_pred = np.asarray(y_pred, dtype=np.float32)\n",
    "    return float(np.sqrt(np.mean((y_pred - y_true) ** 2)))\n",
    "\n",
    "def nrmse(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=np.float32)\n",
    "    return rmse(y_true, y_pred) / float(np.std(y_true))\n",
    "\n",
    "# --- Stratified split by target ---\n",
    "def stratified_split_by_target(y, n_splits=5, seed=42):\n",
    "    y = np.asarray(y, dtype=np.float32)\n",
    "    qs = np.quantile(y, np.linspace(0, 1, 11))\n",
    "    y_bins = np.digitize(y, qs[1:-1])\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    return next(skf.split(np.zeros_like(y_bins), y_bins))\n",
    "\n",
    "# --- Inference of a wrapper on a loader ---\n",
    "@torch.no_grad()\n",
    "def predict_with_wrapper(wrapper, loader, device=\"cuda\"):\n",
    "    wrapper.eval()\n",
    "    preds = []\n",
    "    for batch in tqdm(loader, desc=\"Infer\", leave=False):\n",
    "        if isinstance(batch, (list, tuple)):\n",
    "            x = batch[0]\n",
    "        else:\n",
    "            x = batch\n",
    "        x = x.to(device).float()\n",
    "        y_hat = wrapper(x).squeeze(1)  # (B,)\n",
    "        preds.append(y_hat.detach().cpu().numpy())\n",
    "    return np.concatenate(preds, axis=0)\n",
    "\n",
    "# --- Main evaluation function ---\n",
    "def evaluate_submit_wrapper(wrapper, dataset, targets,\n",
    "                            batch_size=256, num_workers=4,\n",
    "                            n_splits=5, seed=42, device=None):\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    wrapper.to(device)\n",
    "\n",
    "    # train/test indices\n",
    "    train_idx, test_idx = stratified_split_by_target(targets, n_splits=n_splits, seed=seed)\n",
    "\n",
    "    # subsets and loaders\n",
    "    train_ds = Subset(dataset, train_idx)\n",
    "    test_ds  = Subset(dataset, test_idx)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    # predictions\n",
    "    y_pred_train = predict_with_wrapper(wrapper, train_loader, device=device)\n",
    "    y_pred_test  = predict_with_wrapper(wrapper, test_loader,  device=device)\n",
    "\n",
    "    # targets by indices\n",
    "    y_train = np.asarray(targets)[train_idx]\n",
    "    y_test  = np.asarray(targets)[test_idx]\n",
    "\n",
    "    # metrics\n",
    "    rmse_tr, nrmse_tr = rmse(y_train, y_pred_train), nrmse(y_train, y_pred_train)\n",
    "    rmse_te, nrmse_te = rmse(y_test,  y_pred_test),  nrmse(y_test,  y_pred_test)\n",
    "\n",
    "    print(f\"Train: RMSE={rmse_tr:.6f}, NRMSE={nrmse_tr:.6f} | size={len(train_idx)}\")\n",
    "    print(f\"Test : RMSE={rmse_te:.6f}, NRMSE={nrmse_te:.6f} | size={len(test_idx)}\")\n",
    "\n",
    "    return {\n",
    "        \"train_idx\": train_idx,\n",
    "        \"test_idx\": test_idx,\n",
    "        \"y_pred_train\": y_pred_train,\n",
    "        \"y_pred_test\": y_pred_test,\n",
    "        \"rmse_train\": rmse_tr,\n",
    "        \"nrmse_train\": nrmse_tr,\n",
    "        \"rmse_test\": rmse_te,\n",
    "        \"nrmse_test\": nrmse_te,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurosned.wrappers.challenge_1.meta_wrapper import MetaWrapper\n",
    "from neurosned.wrappers.challenge_1.meta_regressor import  MetaRegressor\n",
    "\n",
    "seg_models = [model_1, model_2, model_3, model_4, model_5, model_6]\n",
    "reg = MetaRegressor.load(\"../../artefacts/models/challenge_1/meta_hgb_new.pkl\")\n",
    "fx_hgbr = MetaFeatureExtractor(sfreq=100, win_offset=0.5, temps=(0.5, 0.7, 0.8, 1.))\n",
    "meta_hgbr = MetaWrapper(seg_models=seg_models, cls_models=[],\n",
    "                   feature_extractor=fx_hgbr, meta_regressor=reg,\n",
    "                   use_channels=np.arange(128), device=device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Performance as submission wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: RMSE=0.358030, NRMSE=0.880704 | size=18439\n",
      "Test : RMSE=0.354263, NRMSE=0.883365 | size=4610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "report = evaluate_submit_wrapper(\n",
    "    wrapper=meta_hgbr,\n",
    "    dataset=valid_dataset,         \n",
    "    targets=meta_information_valid['target'].values,  \n",
    "    batch_size=256,\n",
    "    num_workers=4,\n",
    "    n_splits=5,\n",
    "    seed=42,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Blending performance as submission wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: RMSE=0.360137, NRMSE=0.889574 | size=18439\n",
      "Test : RMSE=0.367009, NRMSE=0.899979 | size=4610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from pkg.wrappers.submit_wrapper import SubmitWrapper\n",
    "\n",
    "wrapper = SubmitWrapper(\n",
    "        segmentation_models=[\n",
    "                            model_1, model_2, model_3, model_4, \n",
    "        ], \n",
    "        seg_weights=[       0.3,    0.35,    0.15,    0.2,   ],\n",
    "        use_channels=np.arange(128), temperature=0.92\n",
    "    )\n",
    "\n",
    "\n",
    "report = evaluate_submit_wrapper(\n",
    "    wrapper=wrapper,\n",
    "    dataset=valid_dataset,         \n",
    "    targets=meta_information_valid['target'].values,  \n",
    "    batch_size=256,\n",
    "    num_workers=4,\n",
    "    n_splits=5,\n",
    "    seed=42,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Stacking performance as submission wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: RMSE=0.360112, NRMSE=0.885826 | size=18439\n",
      "Test : RMSE=0.357096, NRMSE=0.890430 | size=4610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "report = evaluate_submit_wrapper(\n",
    "    wrapper=meta_ridge,\n",
    "    dataset=valid_dataset,          \n",
    "    targets=meta_information_valid['target'].values, \n",
    "    batch_size=256,\n",
    "    num_workers=4,\n",
    "    n_splits=5,\n",
    "    seed=42,\n",
    "    device=device,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
